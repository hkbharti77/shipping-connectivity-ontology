# ğŸ“¦ Shipping Connectivity Ontology (LSCI) Project

## ğŸ“˜ Project Overview

This project models global shipping connectivity using the Liner Shipping Connectivity Index (LSCI) as provided by UNCTAD. The goal is to:

* Extract and enrich LSCI data over multiple years
* Build an ontology to represent economies, measurements, and time periods
* Expose the data via a RESTful API with Swagger documentation

---

## ğŸ’‚ï¸ Directory Structure

```
shipping-connectivity-ontology/
â”œâ”€â”€ config/                      # Configuration folder
â”‚   â””â”€â”€ config.toml
â”œâ”€â”€ data/                        # Output enriched and growth data
â”‚   â”œâ”€â”€ lsci_enriched_with_growth.json
â”‚   â””â”€â”€ lsci_growth_trends.csv
â”œâ”€â”€ doc/                         # Source CSV input (e.g., US_LSCI.csv)
â”‚   â””â”€â”€ US_LSCI.csv
â”œâ”€â”€ ontology_objects/           # Object tables like Economy, Period
â”œâ”€â”€ ontology_links/             # Linkage tables (e.g. Economy->LSCI)
â”œâ”€â”€ ontology_output/            # Final assembled ontology (optional)
â”œâ”€â”€ src/                        # Pipeline & analysis scripts
â”‚   â”œâ”€â”€ analytics/              # Trend analysis & scoring
â”‚   â”œâ”€â”€ data_extraction/        # Load & enrich LSCI data
â”‚   â”œâ”€â”€ data_pipeline/          # ETL coordination (if used)
â”‚   â”œâ”€â”€ ontology_definition/    # Define objects and links
â”‚   â”œâ”€â”€ ontology_sim/           # Optional simulation/test ontology logic
â”‚   â””â”€â”€ validation/             # Schema + completeness checks
â”œâ”€â”€ run_local_ontology.py       # Optional runner script
â”œâ”€â”€ LsciApiServer.py            # Flask API (entry point)
â”œâ”€â”€ README.md                   # Project overview
â””â”€â”€ requirements.txt            # Python dependencies

```

---

## ğŸ”„ Workflow Summary

### 1. âœ… Data Extraction & Enrichment

* Fetched LSCI data (fallback to `lsci_data.csv` if API fails)
* Extracted fields: `economy`, `period`, `lsci_value`
* Enriched with:

  * ISO2 / ISO3 country codes
  * UN region (Asia, Europe, etc.)
  * Calculated `growth_rate` using `pct_change()`

### 2. âœ… Ontology Modeling

* **Objects**:

  * `Economy` with ISO codes and region
  * `LSCI_Measurement` with values and growth
  * `Time_Period` (e.g. "2023Q1")
* **Links**:

  * `Economy â†’ MEASURED_BY â†’ LSCI_Measurement`
  * `LSCI_Measurement â†’ RECORDED_IN â†’ Time_Period`

### 3. âœ… API Layer (Flask + Swagger)

* `/` â€” Health check
* `/api/growth` â€” LSCI trends (with optional `economy` filter)
* `/api/enriched` â€” Full enriched dataset (with optional filter)
* `/apidocs` â€” Swagger UI via Flasgger

---

## ğŸš€ How to Run the API

### Prerequisites

* Python 3.11+

### âš™ï¸ Create and Activate a Virtual Environment (Recommended)

Using a virtual environment ensures that dependencies are isolated:

<details>
<summary><strong>ğŸ”¹ For Windows</strong></summary>

```bash
# Create virtual environment
python -m venv venv

# Activate it
venv\Scripts\activate
```

</details>

<details>
<summary><strong>ğŸ”¹ For macOS/Linux</strong></summary>

```bash
# Create virtual environment
python3 -m venv venv

# Activate it
source venv/bin/activate
```

</details>

Then install dependencies inside the environment:

```bash
pip install -r requirements.txt
```

### Run the API

```bash
python api/lsci_api_server.py
```

Visit:

* `http://localhost:5000/` (health check)
* `http://localhost:5000/apidocs` (Swagger UI)

---

## ğŸ“Š Evaluation Criteria Coverage

| Criterion                       | Coverage                                         |
| ------------------------------- | ------------------------------------------------ |
| Relevance of Objects & Linkages | âœ… Defined + linked                               |
| Data Modeling Quality           | âœ… Normalized & enriched                          |
| Completeness                    | âœ… All required fields included                   |
| Flexibility/Extensibility       | âœ… Region & growth support + extendable structure |
| Reasoning Capabilities          | âœ… Trend queries + filters via API                |

---

## âœ¨ Optional Extensions (Future Work)

* Add `CONNECTED_TO` relationships based on LSCI similarity
* Add a frontend dashboard (React + Chart.js)
* Export ontology as YAML or OWL for semantic reasoning
* Deploy with Docker + NGINX for production

---

## ğŸ™Œ Author & Acknowledgements

This project was implemented as part of Stage 1: Ontology & Data Modeling for LSCI. Data provided by [UNCTADstat](https://unctadstat.unctad.org/datacentre/dataviewer/US.LSCI).

---

Feel free to clone, adapt, and extend! ğŸ’¡
